{
    "collab_server" : "",
    "contents" : "library(testthat)\n\n# source file directories\nROOT_ <- \"/Users/wzhou87/Desktop/retrieved_backup/epiProject/walk_bout\"\naccelerometry_phase1 <- file.path(ROOT_,\"data/test/Actigraphy/Phase1\")\naccelerometry_phase2 <- file.path(ROOT_,\"data/test/Actigraphy/Phase2\")\ngps_phase1 <- file.path(ROOT_,\"data/test/GPS/Phase2\")\ngps_phase2 <- file.path(ROOT_,\"data/test/GPS/Phase2\")\n\n####### ####### #######\n#\n# file directory unit tests\n#\n####### ####### #######\n\n# unit-test 1: detect files\ndetect_files <- function(folder){\n  expect_true(file.exists(folder))\n  expect_equal(length(folder),1)\n}\n\n  #detect_files(accelerometry_phase1)\n  detect_files(accelerometry_phase2)\n  #detect_files(gps_phase1)\n  detect_files(gps_phase2)\n\n# unit-test 2: detect directory\ndetect_dir <- function(folder){\n  expect_true(length(strsplit(folder, split = '/')[[1]])>1)\n}\n\n  #detect_dir(accelerometry_phase1)\n  detect_dir(accelerometry_phase2)\n  #detect_dir(gps_phase1)\n  detect_dir(gps_phase2)\n\n# unit test 3: detect csv with metadata leading rows\ndetect_leading_metadata <- function(directory){\n  p = list.files(directory)[1]\n  expect_equal(ncol(read.csv(file.path(directory,p), nrows=10)),1)\n}\n\ndetect_no_leading_metadata <- function(directory){\n  p = list.files(directory)[1]\n  expect_false(ncol(read.csv(file.path(directory,p), nrows=10))==1)\n}\n\n  #detect_leading_metadata(accelerometry_phase1)\n  detect_leading_metadata(accelerometry_phase2)\n  #detect_no_leading_metadata(gps_phase1) # flagged for format issue\n  detect_no_leading_metadata(gps_phase2)\n\n\n####### ####### #######\n#\n# metadata functions\n#\n####### ####### #######\n\n# applied on folders of files\nextract_files <- function(folderpath, pattern=\"*.csv\", ftype='Accelerometry', phase='Phase 1'){\n  #\n  # generate list of files from folder path\n  #\n  # folderpath (dir): the path to a folder of files\n  # pattern (str): pattern to recognize valid files within the folder, e.g., file formats\n  # ftype (str): keyword for the folder\n  # phase (str): keyword for the phase\n\n  meta_tab <- list.files(path = folderpath, pattern = pattern, recursive = TRUE, full.names = TRUE) %>%\n    data.table(path = ., ftype = ftype, phase = phase)\n  return(meta_tab)\n}\n\n\n# applied on all csv files\nparse_fname <- function(fpaths, name_delim=c('\\\\s+\\\\(', '\\\\)', '\\\\DataTable.','\\\\.'), name_list=c('idno','date_start','inc', 'format')){\n  #\n  # extract metadata 1: metadata from filename\n  #\n  # fpaths (list of dir): the file path to be wrangled\n  # name_delim (list of str): list of character patterns for splitting the filename\n  # name_list (list of str): the naming convention for each of the filename components\n\n  # init\n  output_object <- data.table()\n  name_delim <- paste0(name_delim, collapse='|')\n\n  # iterate through all files\n  for (ind in 1:length(fpaths)){\n    # extract filename to list\n    fname = tail(unlist(strsplit(fpaths[ind],'/')),1)\n    fpath <- c(fpaths[ind], fname)\n    names(fpath) <- c('path','fname')\n\n    # parse metadata from fname to list\n    fname_parsed <- unlist(strsplit(fname, name_delim))\n    tryCatch(names(fname_parsed) <- name_list)\n\n    # generate dictionary\n    output_object <- rbindlist(list(output_object, rbind(c(fpath, fname_parsed)) %>% data.table()))\n  }\n  return(output_object)\n}\n\n\n# applied on Accelerometry files\nparse_meta_tuples <- function(fpath, skip_nrows=0, parse_nrows=7, param_delim=c(\"\\\\:\\\\s+\",\"\\\\ \")) {\n  #\n  # extract metadata 2: row-wise tuples\n  #\n  # fpath (dir): the file path to be wrangled\n  # skip_nrows (integer): the number of rows to skip until metadata content, assuming headers are present\n  # parse_nrows (integer): the number of rows containing metadata in row-wise tuples\n  # param_delim (list of str): the delimiters usable for separating metadata name and metadata value\n\n  # init\n  object <- data.table(path=fpath)\n  ac_meta <- read.csv(file=fpath, skip=skip_nrows, nrows = parse_nrows, col.names = \"params\")\n\n  # loop through tuples\n  for (each in ac_meta$params){\n    fragment <- unlist(strsplit(each, split=paste0(param_delim, collapse=\"|\")))\n    object[1, paste0(head(fragment,-1), collapse='_'):=tail(fragment,1)]\n  }\n  return(object)\n}\n\n\n# applied on Accelerometry files\nparse_collapsed_rows <- function(fpath, skip_nrows, parse_nrows, param_delim=c(' \\\\s+'), condensed_delims = c('\\\\: ',' = ')) {\n  #\n  # extract metadata 3: collapsed row\n  #\n  # fpath (dir): the file path to be wrangled\n  # skip_nrows (integer): the number of rows to skip until metadata content starts, assuming headers are present\n  # parse_nrows (integer): the number of rows containing metadata condensed into a collapsed rows of information\n  # param_delim (list of str): the delimiters usable for separating metadata name and metadata value\n\n  #init\n  object = data.table(path=fpath)\n  ac_meta <- read.csv(file=fpath, skip=7, nrows = 1, col.names = \"params\")\n\n  # decompress the collapsed rows\n  fragment <- strsplit(ac_meta$params, split=paste0(param_delim, collapse='|')) %>%\n    unlist() %>%\n    strsplit(split=paste0(condensed_delims, collapse='|'))\n\n  # loop through each collapsed metadata tuple\n  for (eachf in fragment){\n    object[1, eachf[1] := eachf[2]]\n  }\n  return(object)\n}\n\n\n# applied on GPS files\nextract_metadata_from_file <- function (fpath, nrows, date_format=\"%Y/%m/%d\", time_format=\"%H:%M:%S\"){\n  #\n  # extract metadata features from a sample read\n  #\n  # fpath (dir): the file path to be wrangled\n  # nrows (integer): the number of rows to use as metadata samples\n\n  # init read\n  output = read.csv(file=fpath, nrows=nrows, stringsAsFactors = F) %>%\n    mutate(\n      path=fpath,\n      Date = as.POSIXct(LOCAL.DATE, format = date_format), # date\n      Time = format(as.POSIXct(LOCAL.TIME, format = time_format), '%H:%M:%S'), # time\n      DateTime = as.POSIXct(paste(Date, Time), format = '%Y-%m-%d %H:%M:%S'), # datetime, standardized\n      time.difference = DateTime - lag(DateTime)) %>%\n    # group_by(TRACK.ID) %>% # not sure why TRACK.ID seems to be important for separate time-series episodes\n    summarize(path=min(path),\n              date_start=unique(Date) %>% head(1),\n              inc = median(time.difference, na.rm=T), # min or median may not work on singleton NA values if grouping by TRACK.ID\n              Start_Time=format(min(DateTime), '%H:%M:%S'),\n              'Epoch_Period_hms'=as_hms(inc)) %>%\n    data.table()\n  return(output)\n}\n\n\n####### ####### ####### #######\n# Extract accelerometry files\n#\n# function: extract_files\n# function: parse_fname\n# function: parse_meta_tuples\n# function: parse_collapsed_rows\n#\n####### ####### ####### #######\n\n# 1. extract paths\n#paths <- rbindlist(list(extract_files(folderpath=accelerometry_phase1, pattern=\"*.csv\", ftype='Accelerometry', phase='Phase 1'),\n#                        extract_files(folderpath=accelerometry_phase2, pattern=\"*.csv\", ftype='Accelerometry', phase='Phase 2')))\n#' comment everything below\n#paths <- rbindlist(list(extract_files(folderpath=accelerometry_phase2, pattern=\"*.csv\", ftype='Accelerometry', phase='Phase 2')))  # weipeng edit\n#\n#\n## 2. parse the filenames\n#output = parse_fname(fpaths = paths$path, name_delim=c('\\\\s+\\\\(', '\\\\)', 'DataTable.','\\\\.'), name_list=c('idno','date_start','inc', 'format'))\n#paths <- left_join(paths, output, by=\"path\") %>%\n#  mutate(inc=gsub('sec','',inc))\n#\n##%>% mutate(date_start = as.POSIXct(date_start, format = '%Y-%m-%d'))\n## 3. extract tuples\n#output_object <- data.table()\n#for (each in 1:length(paths$path)){\n#  output = parse_meta_tuples(fpath=paths$path[each], skip_nrows=0, parse_nrows=7)\n#  output_object <- rbindlist(list(output_object, output), use.names=TRUE, fill=TRUE)\n#}\n#paths <- left_join(paths, output_object, by=\"path\", all=TRUE)\n#\n## 4. extract collapsed rows metadata\n#output_object <- data.table()\n#for (each in 1:length(paths$path)){\n#  output = parse_collapsed_rows(fpath=paths$path[each], skip_nrows=7, parse_nrows=1, condensed_delims = '\\\\: | = ')\n#  output_object <- rbindlist(list(output_object, output), use.names=TRUE, fill=TRUE)\n#}\n#paths <- left_join(paths, output_object, by='path', all=TRUE)\n#\n#\n######## ####### ####### #######\n##\n## extract GPS file metadata\n##\n######## ####### ####### #######\n#\n## 1. extract paths\n##path1 = data.table(extract_files(folderpath=gps_phase1, pattern=\"*.csv\", ftype='GPS', phase='Phase 1'))\n#path2 = data.table(extract_files(folderpath=gps_phase2, pattern=\"*.csv\", ftype='GPS', phase='Phase 2'))\n#\n## 2. parse the filenames\n##path1 (GPS phase 1) doesn't have the same data structure; looks like clones of Accelerometry Phase 1\n##output = parse_fname(fpaths = path1$path, name_delim=c('\\\\s+\\\\(', '\\\\)', '\\\\DataTable.','\\\\.'), name_list=c('idno','date_start','inc', 'format'))\n##path1 <- left_join(path1, output, by=\"path\")\n#\n#path2 <- parse_fname(fpaths = path2$path,\n#                     name_delim=c('\\\\s+\\\\_', '_CRS.', '_GPS.','\\\\.'),\n#                     name_list=c('idno','format')) %>%\n#  left_join(path2, ., by=\"path\")\n#\n######## ####### ####### ####### #######\n## extract metadata from GPS files\n##\n## function = extract_metadata_from_file\n##\n######## ####### ####### ####### #######\n#\n## 3. Extract metadata from sample rows\n#output_object <- data.table()\n#for (each in 1:length(path2$path)){\n#  object = extract_metadata_from_file(fpath=path2$path[each], nrows=10)\n#  output_object <- rbindlist(list(output_object, object), use.names=TRUE, fill=TRUE)\n#}\n#\n#\n## if clause to prevent recurrent left_joins\n#if (!'TRACK.ID' %in% colnames(path2)){\n#  path2 <- left_join(path2, #>#\n#                     output_object %>%\n#                       mutate(date_start = as.character(date_start),\n#                              inc = as.character(inc)),  # drop date datatype\n#                     by='path', all=TRUE)\n#}\n#\n## compare files and idno mappings\n#path_all = rbindlist(list(paths,\n#                          #path1 %>% select(path, ftype,phase,fname,idno, format), # GPS Phase 1 are clone files\n#                          path2), use.names=TRUE, fill=TRUE) %>%\n#  mutate(ftype_phase = paste0(ftype, \" \", phase))\n#\n## idno dimensions\n#count_fname = path_all %>% dcast(formula = ftype ~ phase, value.var = \"fname\", fun.aggregate=length)\n#\n## idno catalog\n#count_idno = path_all %>% dcast(formula = idno ~ ftype_phase, value.var = \"fname\", fun.aggregate=length)\n#\n## fname catalog\n##type_phase = c('Accelerometry Phase 1',  'GPS Phase 1', 'Accelerometry Phase 2', 'GPS Phase 2')\n#type_phase = c('Accelerometry Phase 2', 'GPS Phase 2')  # weipeng edit\n#fname_usage = path_all %>%\n#  dcast(formula = fname ~ ftype_phase, value.var = \"idno\") %>%\n#  mutate(set_linkage = path_all %>%\n#           dcast(formula = fname ~ ftype_phase, value.var = \"idno\") %>%\n#           select(all_of(type_phase)) %>%\n#           is.na %>%\n#           `!` %>%\n#           rowSums()) %>%\n#  arrange(-set_linkage)\n#\n## filter for non-clones\n#nonclones_ = path_all %>% filter(fname %in% (fname_usage %>% filter(set_linkage==1) %>% .$fname)) # filter for non-clone files\n#\n## filter for clones\n## identifies the shared filenames (clones)\n##clones_ = path_all %>% filter(fname %in% (fname_usage %>% filter(set_linkage>1) %>% .$fname )) # filter for fname\n#\n## how many have multiple filetypes\n#count_idno_nonclone = count_idno %>%\n#  filter(idno %in% (nonclones_ %>% # non-clones\n#                      select(ftype, idno, phase) %>%\n#                      group_by(idno, phase) %>%\n#                      count() %>%\n#                      filter(n>1) %>% # has both accelerometry and GPS\n#                      .$idno)) # 473 have multiple filetypes in Phase 2\n#\n#count_fname_nonclone = path_all %>%\n#  filter(idno %in% count_idno_nonclone$idno) %>% # 473 non-clones with both accelerometry and GPS\n#  filter(fname %in% nonclones_$fname) %>%\n#  dcast(formula = ftype ~ phase, value.var = \"fname\", fun.aggregate=length)\n#\n#\n######## ####### ####### ####### #######\n##\n## metadata search functions\n##\n## function = get_mapped_file\n##\n######## ####### ####### ####### #######\n#\nget_mapped_file <- function(meta_df, fname, ftype){\n  #\n  # find the target file mapped by phase and idno\n  # meta_df (data.table): the data.table of available files. No clones allowed.\n  # fname (dir): the path to the target file\n  # ftype (str): the target file type mapped by idno and phase\n\n  file_meta <- meta_df %>% filter(path == {{fname}})\n  out_file <- meta_df %>%  filter(idno %in% (file_meta$idno),  phase %in% (file_meta$phase),  ftype=={{ftype}})\n\n  #if (length(out_file) == 0){\n  if (nrow(out_file) == 0){  # weipeng edit\n    print('No matching file')\n    return(NULL)\n  } else {\n    return(out_file$path)\n  }\n}\n#\n## find the target file mapped by phase and idno\n##get_mapped_file(meta_df=path_all, fname=path2$path[1], ftype='Accelerometry')\n##get_mapped_file(meta_df=path_all, fname=paths$path[1], ftype='GPS')\n##get_mapped_file(meta_df=path_all, fname=paths$path[1000], ftype='GPS')\n#\n#  ## test: find the target file mapped by phase and idno\n#  #length(get_mapped_file(meta_df=path_all, fname=path2$path[1], ftype='Accelerometry'))==1\n#  #length(get_mapped_file(meta_df=path_all, fname=paths$path[1], ftype='GPS'))==0\n#  #length(get_mapped_file(meta_df=path_all, fname=paths$path[1000], ftype='GPS'))==1\n#\n",
    "created" : 1644455111302.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4174838545",
    "id" : "D1BB4E3E",
    "lastKnownWriteTime" : 1644461109,
    "last_content_update" : 1644461109153,
    "path" : "~/Desktop/retrieved_backup/epiProject/walk_bout/walk_bout_v0.0.2/make_package/rwalkabout/R/metadata_extraction.R",
    "project_path" : "R/metadata_extraction.R",
    "properties" : {
        "marks" : "<:12,17\n>:12,17"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}